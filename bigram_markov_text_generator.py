import random
from collections import defaultdict

'''/////////////////////////////////////////////////////////////////////////////////'''
desiredLength = 1000 #choose the desired number of words
'''/////////////////////////////////////////////////////////////////////////////////'''


'''/////////////////////////////////////////////////////////////////////////////////'''
#then load in desired source document(s) to train the markov model

fileHandle = open('nobel-opening-address.txt', 'r')
sourceText = fileHandle.read()
fileHandle.close()
parsedTextRaw = sourceText.split(' ')


'''/////////////////////////////////////////////////////////////////////////////////'''
# option to strip certain punctuation within words
#punctuation = ['.',',','"','(',')',';','/']
punctuation = ['"','/']

parsedText = []
for word in parsedTextRaw:
    for punct in punctuation:
        if word.find(punct) != -1:
            word = ''.join(ch for ch in word if ch not in punctuation)
    if(len(word) > 0):
        parsedText.append(word)

'''/////////////////////////////////////////////////////////////////////////////////'''
#getNormalizedFrequencyDict takes a textList and a previous word to condition on
    #and then generates a dictionary, where each key is a word
    #and each value is a tuple, each ranging between 0 and 1, eg. (0.25, 0.35)
    #which represents the value range for which random() will choose that key
def getNormalizedFrequencyDict(textList, prevWord=None):
    # counts word frequencies
    wordCounts = defaultdict(int)
    if prevWord == None:
        for word in textList:
            wordCounts[word] += 1
    else:
        index = 0
        for word in textList:
            #if we are conditioning on a prevWord,
            #only count times that this word appears directly after prevWord
            if textList[index-1] == prevWord:
                wordCounts[word] += 1
            index += 1
    totalCount = sum(wordCounts.values())
    probList = []
    probDict = {}
    normalized = wordCounts
    # normalized frequencies and calculates probability ranges
    for key in normalized.keys():
        normalized[key] = float(normalized[key]) / float(totalCount)
        probList.append(key)
        if(len(probList) > 1):
            lastKey = probList[(probList.index(key)-1)]
            probDict[key] = (probDict[lastKey][1], probDict[lastKey][1] + normalized[key])
        else:
            probDict[key] = (0, normalized[key])
    return probDict

#generateAllNormalizedFrequencyDicts takes a textList
    #and pre-generates a dictionary of dictionaries generated by getNormalizedFrequencyDict
    #one conditioned for each possible previous word
def generateAllNormalizedFrequencyDicts(textList):
    allDicts = {}
    allDicts[None] = getNormalizedFrequencyDict(textList)
    for word in parsedText:
        if not word in allDicts:
            conditionedProbDict = getNormalizedFrequencyDict(textList, word)
            allDicts[word] = conditionedProbDict
    return allDicts
'''/////////////////////////////////////////////////////////////////////////////////'''


'''/////////////////////////////////////////////////////////////////////////////////'''
#pre-generate the bigram probablity dictionaries for each word (optimization)
print "Pre-Generating Text Bigrams... Please Wait..."            
allDictsForPrevWord = generateAllNormalizedFrequencyDicts(parsedText)
print "Done Pre-Generating Text\n"
print "Generating Text... Please Wait..."
#to generate each word, use a random number (0,1) to select a random word from the previous word's dictionary
#then append to the generatedText list, and repeat as needed
generatedText = []
for i in range(desiredLength):
    rand = random.random()
    if len(generatedText) > 0:
        # condition on the last generated word
        conditionedProbDict = allDictsForPrevWord[generatedText[-1]]
        for key in conditionedProbDict.keys():
            if rand > conditionedProbDict[key][0] and rand < conditionedProbDict[key][1]:
                generatedText.append(key)
    else:
        #base case: if we haven't generated anything yet, append the first word in the document
        generatedText.append(parsedText[0])
        
#finally, join the array as a string, and print the resulting text document
finalText = ' '.join(generatedText)
print "\n\n" + finalText + "\n\n"
'''/////////////////////////////////////////////////////////////////////////////////'''
